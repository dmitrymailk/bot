{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gradio.app/guides/real-time-speech-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream None\n",
      "new_chunk (48000, array([212, 227, 208, ..., -16, -25, -20], dtype=int16))\n",
      "stream [ 0.05237154  0.05607707  0.0513834  ... -0.00395257 -0.00617589\n",
      " -0.00494071]\n",
      "new_chunk (48000, array([-17, -18, -18, ...,  63,  84,  71], dtype=int16))\n",
      "stream [0.05237154 0.05607707 0.0513834  ... 0.00736928 0.00982571 0.00830507]\n",
      "new_chunk (48000, array([ 76,  72,  80, ..., 703, 726, 768], dtype=int16))\n",
      "stream [0.05237154 0.05607707 0.0513834  ... 0.09410977 0.09718876 0.10281125]\n",
      "new_chunk (48000, array([  790,   784,   781, ..., -3505, -3512, -3583], dtype=int16))\n",
      "stream [ 0.05237154  0.05607707  0.0513834  ... -0.6946096  -0.6959968\n",
      " -0.7100674 ]\n",
      "new_chunk (48000, array([-3597, -3584, -3645, ...,     6,     3,    17], dtype=int16))\n",
      "stream [0.05237154 0.05607707 0.0513834  ... 0.0016225  0.00081125 0.00459708]\n",
      "new_chunk (48000, array([ 10,  19,  22, ..., -19, -18, -15], dtype=int16))\n",
      "stream [ 0.05237154  0.05607707  0.0513834  ... -0.22891566 -0.21686748\n",
      " -0.18072289]\n",
      "new_chunk (48000, array([ -13,  -23,  -18, ..., -203, -191, -168], dtype=int16))\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "\n",
    "def transcribe(stream, new_chunk):\n",
    "    sr, y = new_chunk\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    print(\"stream\", stream)\n",
    "    print(\"new_chunk\", new_chunk)\n",
    "    if stream is not None:\n",
    "        stream = np.concatenate([stream, y])\n",
    "    else:\n",
    "        stream = y\n",
    "    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n",
    "    [\"state\", \"text\"],\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update interface only when special word occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream {'history': array([], dtype=float64)}\n",
      "new_chunk (48000, array([  0,   0,   0, ...,  -3,  -9, -15], dtype=int16))\n",
      "stream {'history': array([ 0.       ,  0.       ,  0.       , ..., -0.0056926, -0.0170778,\n",
      "       -0.028463 ])}\n",
      "new_chunk (48000, array([  -14,   -20,   -16, ..., -3350, -3489, -3486], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.55089623,\n",
      "       -0.57375431, -0.57326096])}\n",
      "new_chunk (48000, array([-3497, -3539, -3456, ...,    16,    22,    40], dtype=int16))\n",
      "stream {'history': array([0.        , 0.        , 0.        , ..., 0.00442356, 0.00608239,\n",
      "       0.01105889])}\n",
      "new_chunk (48000, array([ 33,  28,  24, ..., -30, -43, -40], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.34090909,\n",
      "       -0.48863637, -0.45454547])}\n",
      "new_chunk (48000, array([-47, -53, -55, ..., -21, -14, -19], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.28      ,\n",
      "       -0.18666667, -0.25333333])}\n",
      "new_chunk (48000, array([-27, -22, -25, ...,   3,   4,   6], dtype=int16))\n",
      "stream {'history': array([0.        , 0.        , 0.        , ..., 0.03157895, 0.04210526,\n",
      "       0.06315789])}\n",
      "new_chunk (48000, array([  3,  12,  19, ..., -31, -19, -24], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.27433628,\n",
      "       -0.16814159, -0.21238938])}\n",
      "new_chunk (48000, array([-14, -23, -14, ...,   6,   0,  -4], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ...,  0.08219178,\n",
      "        0.        , -0.05479452])}\n",
      "new_chunk (48000, array([-11,  -3,   4, ...,   0,  -3,  -1], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "       -0.04166667, -0.01388889])}\n",
      "new_chunk (48000, array([  1,   4,   7, ..., -11,  -6, -10], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.1641791 ,\n",
      "       -0.08955224, -0.14925373])}\n",
      "new_chunk (48000, array([  -10,    -1,    -3, ..., -1940, -1743, -1604], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.22600186,\n",
      "       -0.20305219, -0.18685928])}\n",
      "new_chunk (48000, array([-1515, -1357, -1280, ...,    51,    41,    62], dtype=int16))\n",
      "stream {'history': array([0.        , 0.        , 0.        , ..., 0.00550459, 0.00442526,\n",
      "       0.00669185])}\n",
      "new_chunk (48000, array([ 42,  11,   7, ...,  -3, -23, -31], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.02654867,\n",
      "       -0.20353982, -0.27433628])}\n",
      "new_chunk (48000, array([-20, -15, -25, ...,   3, -24, -38], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ...,  0.02521008,\n",
      "       -0.20168068, -0.31932774])}\n",
      "new_chunk (48000, array([-39, -24,  -5, ..., -11, -13, -26], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.08029197,\n",
      "       -0.09489051, -0.18978103])}\n",
      "new_chunk (48000, array([-14, -22,  12, ..., 612, 616, 764], dtype=int16))\n",
      "stream {'history': array([0.        , 0.        , 0.        , ..., 0.08491744, 0.08547246,\n",
      "       0.10600805])}\n",
      "new_chunk (48000, array([842, 943, 916, ..., -19, -26, -44], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.00356473,\n",
      "       -0.00487805, -0.00825516])}\n",
      "new_chunk (48000, array([-39, -17,  -7, ...,   4,  -4, -20], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ...,  0.02139037,\n",
      "       -0.02139037, -0.10695187])}\n",
      "new_chunk (48000, array([-30, -24,   4, ..., -42, -32, -16], dtype=int16))\n",
      "stream {'history': array([ 0.        ,  0.        ,  0.        , ..., -0.20289855,\n",
      "       -0.15458937, -0.07729468])}\n",
      "new_chunk (48000, array([  3,   3, -17, ...,  72,  60,  98], dtype=int16))\n",
      "stream {'history': array([0.        , 0.        , 0.        , ..., 0.16071428, 0.13392857,\n",
      "       0.21875   ])}\n",
      "new_chunk (48000, array([  101,    52,    54, ...,  -995, -1014,  -972], dtype=int16))\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "\n",
    "def transcribe(stream, new_chunk):\n",
    "    sr, y = new_chunk\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    print(\"stream\", stream)\n",
    "    print(\"new_chunk\", new_chunk)\n",
    "\n",
    "    stream[\"history\"] = np.concatenate([stream[\"history\"], y])\n",
    "    predicted_text = transcriber(\n",
    "        {\n",
    "            \"sampling_rate\": sr,\n",
    "            \"raw\": stream[\"history\"],\n",
    "        }\n",
    "    )[\"text\"]\n",
    "    \n",
    "    render_text = predicted_text\n",
    "    if stream[\"prev_text\"] != predicted_text:\n",
    "        stream[\"prev_text\"] = predicted_text\n",
    "    else:\n",
    "        render_text = stream[\"prev_text\"]\n",
    "\n",
    "    return (\n",
    "        stream,\n",
    "        render_text,\n",
    "    )\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    [\n",
    "        gr.State(value={\"history\": np.array([]), \"prev_text\": \"\"}),\n",
    "        gr.Audio(sources=[\"microphone\"], streaming=True),\n",
    "    ],\n",
    "    [gr.State(), \"text\"],\n",
    "    # live=True,\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
