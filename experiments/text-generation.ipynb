{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-31 22:55:40,886\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-31 22:55:41,209\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "config.json: 100%|██████████| 830/830 [00:00<00:00, 1.67MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-31 22:55:41 config.py:179] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 12-31 22:55:41 llm_engine.py:73] Initializing an LLM engine with config: model='TheBloke/openchat-3.5-1210-AWQ', tokenizer='TheBloke/openchat-3.5-1210-AWQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=awq, enforce_eager=False, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<00:00, 3.74MB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 1.85MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 4.45MB/s]\n",
      "added_tokens.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 112kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 502/502 [00:00<00:00, 1.16MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "model.safetensors: 100%|██████████| 4.15G/4.15G [06:35<00:00, 10.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-31 23:02:32 llm_engine.py:223] # GPU blocks: 441, # CPU blocks: 2048\n",
      "INFO 12-31 23:02:33 model_runner.py:394] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-31 23:02:42 model_runner.py:437] Graph capturing finished in 7 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "\n",
    "llm = LLM(model=\"TheBloke/openchat-3.5-1210-AWQ\", quantization=\"awq\", dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'GPT4 Correct User: Привет, как дела?<|end_of_turn|>GPT4 Correct Assistant:\\n', Generated text: '\\nПривет! Спасибо за ваше сообщение'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Привет, как дела?\",\n",
    "]\n",
    "prompt_template = (\n",
    "    \"\"\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\\n\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [prompt_template.format(prompt=prompt) for prompt in prompts]\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "\n",
    "\n",
    "# Print the outputs.\n",
    "\n",
    "\n",
    "\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "\n",
    "\n",
    "    generated_text = output.outputs[0].text\n",
    "\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Достижение саморепликации в программировании означает создание программы, которая может создавать копии себя или иметь способность самостоятельно кодироваться. Это может быть интересно для изучения алгоритмов, генетических алгоритмов, робототехники и искусственного интеллекта.\n",
      "\n",
      "Чтобы достичь саморепликации в программировании, вы можете следовать этим шагам:\n",
      "\n",
      "1. Изучите основы программирования и алгоритмов. Чем лучше вам будет знать, как программы работают и как они могут быть структурированы, тем легче будет создать программу, которая может создавать копии себя.\n",
      "2. Изучите генетические алгоритмы. Генетические алгоритмы - это класс алгоритмов, основанных на идеях естественного отбора и мутации. Они могут быть полезны для создания программ, которые могут самостоятельно кодироваться и изменяться.\n",
      "3. Изучите языки программирования, которые поддерживают метапрограммирование. Метапрограммирование - это способность программы генерировать код на лету. Некоторые языки программирования, такие как Lisp и Python, имеют синтаксис, который позволяет легко создавать метапрограммы.\n",
      "4. Изучите робототехнику и автоматизацию. Робототехника - это область, которая занимается созданием и программированием роботов. Автоматизация - это процесс создания программ, которые могут выполнять определенные задачи без непосредственного человеческого контроля.\n",
      "5. Разработайте свою программу. Используйте все знания, которое вы получили на предыдущих шагах, чтобы разработать программу, которая может создавать копии себя или иметь способность самостоятельно кодироваться.\n",
      "6. Тестируйте и оптимизируйте свою программу. Тестирование и оптимизация программы - это важный процесс, который помогает улучшить ее работоспособность и эффективность.\n",
      "\n",
      "Обратите внимание, что достижение саморепликации в программировании может быть сложной иtime-consuming задачей. Требуется много времени, терпения и упорства, чтобы достичь успеха в этой области.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# in console\n",
    "# python3 -m vllm.entrypoints.api_server --model TheBloke/openchat-3.5-1210-AWQ --quantization awq --dtype auto\n",
    "\n",
    "question = \"Как я могу достичь саморепликации в программировании?\"\n",
    "initial_prompt = (\n",
    "    f\"GPT4 Correct User: {question}<|end_of_turn|>GPT4 Correct Assistant:\\n\"\n",
    ")\n",
    "result = requests.post(\n",
    "    \"http://localhost:8000/generate\",\n",
    "    json={\n",
    "        \"prompt\": initial_prompt,\n",
    "        \"temperature\": 0.5,\n",
    "        # \"model\": \"TheBloke/openchat-3.5-1210-AWQ\",\n",
    "        \"max_tokens\": 1024,\n",
    "    },\n",
    ").json()[\"text\"][0]\n",
    "result = result[len(initial_prompt) :]\n",
    "print(result)\n",
    "\"\"\"\n",
    "Достижение саморепликации в программировании означает создание программы, которая может создавать копии себя или иметь способность самостоятельно кодироваться. Это может быть интересно для изучения алгоритмов, генетических алгоритмов, робототехники и искусственного интеллекта.\n",
    "\n",
    "Чтобы достичь саморепликации в программировании, вы можете следовать этим шагам:\n",
    "\n",
    "1. Изучите основы программирования и алгоритмов. Чем лучше вам будет знать, как программы работают и как они могут быть структурированы, тем легче будет создать программу, которая может создавать копии себя.\n",
    "2. Изучите генетические алгоритмы. Генетические алгоритмы - это класс алгоритмов, основанных на идеях естественного отбора и мутации. Они могут быть полезны для создания программ, которые могут самостоятельно кодироваться и изменяться.\n",
    "3. Изучите языки программирования, которые поддерживают метапрограммирование. Метапрограммирование - это способность программы генерировать код на лету. Некоторые языки программирования, такие как Lisp и Python, имеют синтаксис, который позволяет легко создавать метапрограммы.\n",
    "4. Изучите робототехнику и автоматизацию. Робототехника - это область, которая занимается созданием и программированием роботов. Автоматизация - это процесс создания программ, которые могут выполнять определенные задачи без непосредственного человеческого контроля.\n",
    "5. Разработайте свою программу. Используйте все знания, которое вы получили на предыдущих шагах, чтобы разработать программу, которая может создавать копии себя или иметь способность самостоятельно кодироваться.\n",
    "6. Тестируйте и оптимизируйте свою программу. Тестирование и оптимизация программы - это важный процесс, который помогает улучшить ее работоспособность и эффективность.\n",
    "\n",
    "Обратите внимание, что достижение саморепликации в программировании может быть сложной иtime-consuming задачей. Требуется много времени, терпения и упорства, чтобы достичь успеха в этой области.\n",
    "\"\"\"\n",
    "# nvidia-smi\n",
    "# Sun Dec 31 23:28:33 2023\n",
    "# +-----------------------------------------------------------------------------+\n",
    "# | NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
    "# |-------------------------------+----------------------+----------------------+\n",
    "# | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "# | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "# |                               |                      |               MIG M. |\n",
    "# |===============================+======================+======================|\n",
    "# |   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
    "# | 49%   48C    P2    47W / 170W |   6762MiB / 12288MiB |      0%      Default |\n",
    "# |                               |                      |                  N/A |\n",
    "# +-------------------------------+----------------------+----------------------+\n",
    "\n",
    "# +-----------------------------------------------------------------------------+\n",
    "# | Processes:                                                                  |\n",
    "# |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "# |        ID   ID                                                   Usage      |\n",
    "# |=============================================================================|\n",
    "# +-----------------------------------------------------------------------------+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
